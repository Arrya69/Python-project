{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6y2Yk1Kt-aJ",
    "outputId": "21599b73-996b-48ea-8633-66ef5e745ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (8.3.68)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (1.9.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\.conda\\envs\\foodrecognition\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHxt5C7OB8vu",
    "outputId": "4bcada3e-c0d7-453e-d19e-045b26fd99bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\n",
      "License(s): CC0-1.0\n",
      "fruit-and-vegetable-image-recognition.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d kritikseth/fruit-and-vegetable-image-recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwHjXHUYB_2l",
    "outputId": "13bb14f1-bdc7-4145-9353-37314468ef91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip fruit-and-vegetable-image-recognition.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Define paths\n",
    "zip_file_path = \"C:/Users/HP/Downloads/Food Recogntion 2024/Code/fruit-and-vegetable-image-recognition.zip\"  # Replace with your ZIP file's path\n",
    "extraction_path = \"C:/Users/HP/Downloads/Food Recogntion 2024/Code\"  # Replace with the desired extraction folder\n",
    "\n",
    "# Extract the ZIP file\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extraction_path)\n",
    "    print(\"Extraction completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rn3f2RYRCUnf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file dataset already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 dir(s) moved.\n",
      "        1 dir(s) moved.\n",
      "        1 dir(s) moved.\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\n",
    "!move test dataset\n",
    "!move train dataset\n",
    "!move validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exists: True\n",
      "YOLO model initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO  # Ensure you have ultralytics installed: pip install ultralytics\n",
    "\n",
    "# Define the path to your custom dataset\n",
    "dataset_path = \"C:/Users/HP/Downloads/Food Recogntion 2024/Code/dataset\"\n",
    "\n",
    "# Check if the dataset path exists\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Dataset exists:\", True)\n",
    "else:\n",
    "    print(\"Dataset does not exist:\", False)\n",
    "\n",
    "# Initialize the YOLO model with pre-trained weights\n",
    "model = YOLO(\"yolov8n-cls.pt\")  # Ensure the .pt file exists in your working directory\n",
    "print(\"YOLO model initialized successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NgKVOMKHuEIV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9o2G3zKz6lpZ",
    "outputId": "19182af3-99c0-46af-ae48-a4aec029051e"
   },
   "outputs": [],
   "source": [
    "# Define the path to your custom dataset\n",
    "dataset_path = \"C:/Users/HP/Downloads/Food Recogntion 2024/Code/dataset\"\n",
    "\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"yolov8n-cls.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-Vicl6phtSg",
    "outputId": "769eefd8-4326-4cd0-c826-c1f98c6953c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.71 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.68  Python-3.8.20 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-1155G7 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:/Users/HP/Downloads/Food Recogntion 2024/Code/dataset, epochs=20, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train7\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train... found 3115 images in 36 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\validation... found 351 images in 36 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\test... found 359 images in 36 classes  \n",
      "Overriding model.yaml nc=1000 with nc=36\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    376356  ultralytics.nn.modules.head.Classify         [256, 36]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1,484,404 parameters, 1,484,404 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train7', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train... 3114 images, 1 corrupt: 100%|██████████| 3114/3114 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\apple\\Image_50.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\bell pepper\\Image_56.jpg: ignoring corrupt image/label: Invalid image format GIF. Supported formats are:\n",
      "images: {'jpeg', 'tif', 'tiff', 'png', 'mpo', 'bmp', 'jpg', 'pfm', 'heic', 'webp', 'dng'}\n",
      "videos: {'avi', 'asf', 'webm', 'mkv', 'm4v', 'mov', 'mp4', 'gif', 'mpg', 'wmv', 'mpeg', 'ts'}\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\carrot\\Image_17.jpeg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\carrot\\Image_51.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\carrot\\Image_69.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\tomato\\Image_65.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\validation... 351 images, 0 corrupt: 100%|██████████| 351/351 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00025, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train7\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      3.424         10        224: 100%|██████████| 195/195 [04:36<00:00,  1.42s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:19<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.507      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      2.394         10        224: 100%|██████████| 195/195 [04:33<00:00,  1.40s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:37<00:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.778      0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G       1.41         10        224: 100%|██████████| 195/195 [06:09<00:00,  1.90s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:55<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.835      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      1.009         10        224: 100%|██████████| 195/195 [07:11<00:00,  2.21s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:53<00:00,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.88      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G     0.8428         10        224: 100%|██████████| 195/195 [07:09<00:00,  2.20s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:20<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.892      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G     0.7582         16        224:  52%|█████▏    | 101/195 [02:36<01:15,  1.25it/s]"
     ]
    }
   ],
   "source": [
    "# Train the model on your custom dataset\n",
    "results = model.train(data=dataset_path, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc = [0.507, 0.778, 0.835, 0.88, 0.892]\n",
    "top5_acc = [0.803, 0.974, 0.991, 0.989, 0.991]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, top1_acc, marker='o', linestyle='-', color='g', label=\"Top-1 Accuracy\")\n",
    "plt.plot(epochs, top5_acc, marker='o', linestyle='-', color='r', label=\"Top-5 Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KF0TP82v0kWi",
    "outputId": "55713752-ba4d-46b5-9867-355ab64312a8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print the training results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the training results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gV7lgmb-8iBp"
   },
   "outputs": [],
   "source": [
    "#Load the best trained model\n",
    "Model = YOLO('C:/Users/HP/Downloads/Food Recogntion 2024/Code/runs/classify/train5/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCaKd__bUdSd"
   },
   "source": [
    "Test a random example for internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "ZHLJx3HTugri",
    "outputId": "c625adef-6074-4691-c03a-59a25b6a0097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\HP\\Downloads\\Food Recogntion 2024\\Code\\dataset\\train\\tomato\\Image_91.jpg: 224x224 tomato 0.93, capsicum 0.04, bell pepper 0.02, paprika 0.01, pomegranate 0.00, 64.2ms\n",
      "Speed: 54.8ms preprocess, 64.2ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tomato'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = Model(\"C:/Users/HP/Downloads/Food Recogntion 2024/Code/dataset/train/tomato/Image_91.jpg\")\n",
    "\n",
    "# Extract the predicted class name as a string\n",
    "prediction[0].names[prediction[0].probs.top1]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (foodrecognition)",
   "language": "python",
   "name": "foodrecognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
